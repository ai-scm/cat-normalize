# üöÄ Cat Prod Normalize - Multi-Stack Data Pipeline

Sistema ETL completo para el procesamiento automatizado de conversaciones del chatbot **Catia**, implementado con AWS CDK como pipeline de datos empresarial.

Este proyecto implementa un **sistema de an√°lisis multi-fuente** para conversaciones del chatbot Catia, con dos pipelines independientes: uno para an√°lisis de conversaciones y feedback, y otro para an√°lisis de costos de tokens de Amazon Bedrock Claude Sonnet 3.5.

### üéØ **Objetivos del Sistema**
- **Pipeline ETL Principal**: Conversaciones DynamoDB ‚Üí S3 ‚Üí Athena (Stacks 1-2)
- **Pipeline Tokens Multi-Ambiente**: An√°lisis de costos Claude con procesamiento hist√≥rico y consolidado (Stack 3)
- **An√°lisis de Costos Bedrock**: C√°lculo de tokens y estimaciones de costos AWS
- **Optimizaci√≥n de Datos**: Conversi√≥n CSV ‚Üí Parquet para consultas eficientes
- **Escalabilidad**: Arquitectura serverless multi-stack independiente
- **Monitoreo**: Tags detallados para Cost Explorer y billing por componente

## üèóÔ∏è Arquitectura Multi-Stack Independiente

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                        üîÑ PIPELINE PRINCIPAL (Stacks 1-2)                   ‚îÇ
‚îÇ                           An√°lisis de Conversaciones                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ DynamoDB-1  ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ Lambda ETL-1‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ   S3 CSV    ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ Glue ETL-2  ‚îÇ
‚îÇConversations‚îÇ    ‚îÇ(Normalize)  ‚îÇ    ‚îÇ Raw Reports ‚îÇ    ‚îÇ(Transform)  ‚îÇ
‚îÇ    Table    ‚îÇ    ‚îÇ             ‚îÇ    ‚îÇ             ‚îÇ    ‚îÇ             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                           ‚îÇ                                        ‚îÇ
                           ‚ñº                                        ‚ñº
                   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                   ‚îÇEventBridge  ‚îÇ                          ‚îÇ S3 Parquet  ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂ Athena
                   ‚îÇ Scheduler   ‚îÇ                          ‚îÇOptimized DB ‚îÇ     Analytics
                   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                                                    ‚îÇ
                                                                    ‚ñº
                                                            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                                                            ‚îÇGlue Crawler ‚îÇ
                                                            ‚îÇAuto-Schema  ‚îÇ
                                                            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    ü™ô PIPELINE TOKENS (Stack 3)                             ‚îÇ
‚îÇ          An√°lisis de Tokens con Procesamiento Dual (Multi-Ambiente)         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  DynamoDB    ‚îÇ         ‚îÇ   Lambda 1       ‚îÇ        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Old Table   ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ   Archival       ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ S3 Bucket   ‚îÇ
‚îÇ (Historical) ‚îÇ         ‚îÇ  (One-time)      ‚îÇ        ‚îÇ historical/ ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                                             ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê               ‚îÇ
‚îÇ  DynamoDB    ‚îÇ         ‚îÇ   Lambda 2       ‚îÇ               ‚ñº
‚îÇ  New Table   ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  Consolidated    ‚îÇ        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  (Current)   ‚îÇ         ‚îÇ   (Daily)        ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ S3 Bucket   ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂ Athena
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò        ‚îÇconsolidated/‚îÇ     View
                                 ‚îÇ                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                 ‚ñº
                         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                         ‚îÇ  EventBridge     ‚îÇ
                         ‚îÇ (Test: Disabled) ‚îÇ
                         ‚îÇ (Prod: Daily)    ‚îÇ
                         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## üìÅ Estructura del Proyecto

```
cat-prod-normalize/
‚îú‚îÄ‚îÄ üìì notebook/                                    # C√≥digo origen de referencia
‚îÇ   ‚îú‚îÄ‚îÄ cat-prod-normalize-data.ipynb               # Notebook original
‚îÇ   ‚îî‚îÄ‚îÄ cat_prod_normalize_script.py                # Script convertido
‚îú‚îÄ‚îÄ üêç lambda/                                      # Funciones Lambda multi-ETL
‚îÇ   ‚îú‚îÄ‚îÄ README.md                                   # Documentaci√≥n ETL espec√≠fica
‚îÇ   ‚îú‚îÄ‚îÄ etl-process1/                               # üîÑ ETL-1: Extracci√≥n y normalizaci√≥n
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ lambda_function.py                      # Core: DynamoDB ‚Üí CSV
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt                        # pandas, boto3, numpy
‚îÇ   ‚îú‚îÄ‚îÄ etl-process2/                               # üîÑ ETL-2: Transformaci√≥n a Parquet
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ glue_job_script.py                      # Glue: CSV ‚Üí Parquet + tokens
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt                        # tiktoken, pyspark
‚îÇ   ‚îî‚îÄ‚îÄ tokens-process/                             # üí∞ An√°lisis de tokens (Dual Lambda)
‚îÇ       ‚îú‚îÄ‚îÄ README.md                               # üìñ Documentaci√≥n detallada
‚îÇ       ‚îú‚îÄ‚îÄ lambda-tokens-archival-processing.py    # Lambda 1: Procesar tabla antigua
‚îÇ       ‚îú‚îÄ‚îÄ tokens_lambda.py                        # Lambda 2: Consolidar datos
‚îÇ       ‚îî‚îÄ‚îÄ requirements.txt                        # pandas, boto3
‚îú‚îÄ‚îÄ üìö lib/                                         # Definiciones CDK (3 stacks)
‚îÇ   ‚îú‚îÄ‚îÄ configs/                                    # üÜï Configuraciones por ambiente
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tokens-config.interface.ts              # TypeScript interface
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test-tokens.config.ts                   # Config para TEST
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ prod-tokens.config.ts                   # Config para PROD
‚îÇ   ‚îú‚îÄ‚îÄ constructs/                                 # Componentes reutilizables
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ athena-construct.ts                     # WorkGroup Athena
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ catalog-construct.ts                    # Glue Database + Crawler
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ orchestrator-construct.ts               # EventBridge automation
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ transform-job-construct.ts              # Glue Job ETL-2
‚îÇ   ‚îî‚îÄ‚îÄ stacks/                                     # üèóÔ∏è 3 Stacks principales
‚îÇ       ‚îú‚îÄ‚îÄ cat-prod-normalize-stack.ts             # Stack 1: ETL-1 (Lambda)
‚îÇ       ‚îú‚îÄ‚îÄ cad-prod-etl-stack.ts                   # Stack 2: ETL-2 (Glue)
‚îÇ       ‚îî‚îÄ‚îÄ cat-prod-tokens-stack.ts                # Stack 3: Tokens (Dual Lambda)
‚îú‚îÄ‚îÄ üéØ bin/                                         # Punto de entrada
‚îÇ   ‚îî‚îÄ‚îÄ cat-prod-normalize.ts                       # App CDK multi-stack multi-env
‚îú‚îÄ‚îÄ ‚öôÔ∏è config/                                      # Configuraci√≥n centralizada
‚îÇ   ‚îú‚îÄ‚îÄ accountConfig.json                          # Cuenta AWS (081899001252)
‚îÇ   ‚îú‚îÄ‚îÄ config.json                                 # Namespace (cat-prod)
‚îÇ   ‚îî‚îÄ‚îÄ tags.json                                   # Tags est√°ndar (P0260)
‚îú‚îÄ‚îÄ üß™ test/                                        # Tests unitarios
‚îÇ   ‚îî‚îÄ‚îÄ cat-prod-normalize.test.ts                  # Tests CDK
‚îî‚îÄ‚îÄ üìã archivos ra√≠z
    ‚îú‚îÄ‚îÄ README.md                                   # Este archivo
    ‚îú‚îÄ‚îÄ package.json                                # Dependencias Node.js
    ‚îú‚îÄ‚îÄ cdk.json                                    # Configuraci√≥n CDK
    ‚îú‚îÄ‚îÄ tsconfig.json                               # TypeScript config
    ‚îî‚îÄ‚îÄ test_token_functions.py                     # Test tokens local
```

## üè≠ Stacks y Recursos Desplegados

### **üîÑ Stack 1: `cat-prod-normalize-stack` (ETL-1)**
**Prop√≥sito**: Extracci√≥n y normalizaci√≥n desde DynamoDB

| Recurso | Nombre | Descripci√≥n |
|---------|---------|-------------|
| üêç **Lambda** | `cat-prod-lambda-normalize` | ETL-1: DynamoDB ‚Üí CSV (12 columnas) |
| üì¶ **S3 Bucket** | `cat-prod-normalize-reports` | Data Lake central |
| üîê **IAM Role** | `CatProdNormalizeETLLambdaRole` | Permisos DynamoDB + S3 |
| ‚è∞ **EventBridge** | `cat-prod-daily-etl-schedule` | Trigger diario 11:30 PM COL |
| üìä **Layer** | `AWSSDKPandas-Python39:13` | Dependencias (pandas, boto3) |

### **üîÑ Stack 2: `cat-prod-etl2-stack` (ETL-2)**
**Prop√≥sito**: Transformaci√≥n a formato anal√≠tico optimizado

| Recurso | Nombre | Descripci√≥n |
|---------|---------|-------------|
| ‚ö° **Glue Job** | `cat-prod-etl2-parquet` | ETL-2: CSV ‚Üí Parquet + tokens |
| üï∑Ô∏è **Glue Crawler** | `curated-crawler` | Auto-detecci√≥n de esquemas |
| üóÑÔ∏è **Glue Database** | `cat_prod_analytics_db` | Cat√°logo de metadatos |
| üîç **Athena WorkGroup** | `wg-cat-prod-analytics` | Consultas SQL optimizadas |
| üîê **IAM Roles** | Multiple | Permisos Glue + S3 + EventBridge |
| üéØ **EventBridge** | `S3 Object Created` | Trigger autom√°tico ETL-2 |

### **üí∞ Stack 3: `cat-{env}-tokens-stack` (An√°lisis Tokens - Multi-Ambiente)**
**Prop√≥sito**: An√°lisis dual de tokens con procesamiento hist√≥rico y consolidado

| Recurso | Nombre | Descripci√≥n |
|---------|---------|-------------|
| üêç **Lambda 1** | `cat-{env}-lambda-tokens-archival` | Procesa tabla antigua (one-time) |
| üêç **Lambda 2** | `cat-{env}-lambda-tokens-consolidated` | Procesa nueva tabla + consolida (daily) |
| üìä **Layer** | `cat-{env}-pandas-numpy-layer` | pandas, numpy, boto3 (Python 3.11) |
| üîê **IAM Roles** | 2 roles independientes | Permisos espec√≠ficos por Lambda |
| ‚è∞ **EventBridge** | `{env}-cat-daily-tokens-schedule` | Test: Disabled, Prod: Daily |
| üóÑÔ∏è **Data Sources** | Old + New DynamoDB Tables | Procesamiento dual |
| üìÇ **S3 Outputs** | `historical/` + `consolidated/` | Datos hist√≥ricos + consolidados |

**Configuraci√≥n por Ambiente**:
- **Test**: Schedule deshabilitado, ejecuci√≥n manual, 1GB RAM
- **Prod**: Schedule diario 4:30 AM UTC, 2GB RAM, retry autom√°tico

### **üéØ Fase 1: ETL-1 (Lambda Normalize)**
1. **Trigger**: EventBridge Schedule `cron(30 4 * * ? *)` (UTC)
2. **Fuente**: DynamoDB Nadia 2
3. **Procesamiento**: 
   - Normalizaci√≥n de usuarios √∫nicos por `user_id`
   - Extracci√≥n de preguntas desde JSON `conversation_history`
   - Clasificaci√≥n de feedback: `like/dislike/mixed`
   - Merge de tablas conversations + feedback
4. **Salida**: `s3://cat-prod-normalize-reports/reports/etl-process1/data_YYYYMMDD.csv`

### **üéØ Fase 2: ETL-2 (Glue Transform)**
1. **Trigger**: S3 Event `ObjectCreated` en `/etl-process1/`
2. **Motor**: Glue Job con Spark (2 workers G.1X)
3. **Procesamiento**:
   - Lectura CSV m√°s reciente con PySpark
   - Conversi√≥n de tipos de datos optimizada
   - **C√°lculo de tokens** con biblioteca `tiktoken`
   - Generaci√≥n de archivo Parquet √∫nico
4. **Salida**: `s3://cat-prod-normalize-reports/reports/etl-process2/data.parquet`

### **üéØ Fase 3: Catalogaci√≥n Autom√°tica**
1. **Trigger**: Glue Job State Change ‚Üí `SUCCEEDED`
2. **Acci√≥n**: Crawler escanea `/etl-process2/data.parquet/`
3. **Resultado**: Schema actualizado en `cat_prod_analytics_db`
4. **Disponibilidad**: Tabla lista para consultas Athena

### **üéØ Fase 4: An√°lisis de Tokens (Dual Lambda - Multi-Ambiente)**

**Arquitectura de Dos Fases**:

**Fase 4.1: Procesamiento Hist√≥rico (Lambda Archival - ONE-TIME)**
1. **Ejecuci√≥n**: Manual, una sola vez por ambiente
2. **Fuente**: Tabla DynamoDB antigua (datos hist√≥ricos pre-migraci√≥n)
3. **L√≥gica**: Algoritmo de extracci√≥n original (compatible con formato antiguo)
4. **Procesamiento**:
   - Lee tabla antigua completa
   - Filtra por rango de fechas configurado (ej: 2025-08-04 a 2025-12-31)
   - Calcula tokens: `LENGTH(text) / 4`
   - Genera estad√≠sticas de costos
5. **Salida**: `s3://{env}/archives/tokens-analysis/tokens_analysis_old_table.csv`
6. **Config**: Timeout 15min, Memory 1-2GB (test/prod)

**Fase 4.2: Procesamiento Consolidado (Lambda Consolidated - DAILY)**
1. **Trigger**: EventBridge Schedule 
2. **Fuente**: Tabla DynamoDB nueva (datos actuales post-migraci√≥n)
3. **L√≥gica**: Algoritmo v2 con soporte para `toolUse/toolResult` (nuevo formato)
4. **Procesamiento**:
   - Lee tabla nueva (datos desde fecha de migraci√≥n)
   - Aplica l√≥gica mejorada de tokens
   - Lee datos hist√≥ricos desde S3
   - **Consolida** ambas fuentes
   - Genera CSV √∫nico con columna `source` (old_table/new_table)
   - Actualiza vista Athena autom√°ticamente
5. **Salida**: `s3://cat-{env}-normalize-reports/tokens-analysis/tokens_analysis_consolidated.csv`
6. **Config**: Timeout 5min, Memory 512MB
7. **Schedule**: 
   - Test: Deshabilitado (ejecuci√≥n manual)
   - Prod: Habilitado (diario 11:30 PM Colombia)

**Configuraci√≥n por Ambiente** (TypeScript):
```typescript
// lib/configs/test-tokens.config.ts
export const testTokensConfig: TokensConfig = {
  environment: 'test',
  oldDynamoTableName: 'old-test-table',
  newDynamoTableName: 'new-test-table',
  outputBucket: 'cat-test-normalize-reports',
  schedule: { enabled: false },  // Manual only
  // ... m√°s configuraciones
};

// lib/configs/prod-tokens.config.ts
export const prodTokensConfig: TokensConfig = {
  environment: 'prod',
  oldDynamoTableName: 'BedrockChatStack-Old',
  newDynamoTableName: 'BedrockChatStack-New',
  outputBucket: 'cat-prod-normalize-reports',
  schedule: { enabled: true, cronExpression: 'cron(30 4 * * ? *)' },
  // ... m√°s configuraciones
};
```

> **üìù Nota**: Stack 3 usa configuraci√≥n TypeScript multi-ambiente. Ver `lambda/tokens-process/README.md` para detalles t√©cnicos.

## üìä Esquema de Datos Final

### **üóÇÔ∏è Columnas del Dataset Principal (12 campos)**

| # | Columna | Tipo | Descripci√≥n | Origen |
|---|---------|------|-------------|--------|
| 1 | `usuario_id` | String | ID √∫nico del usuario | DynamoDB |
| 2 | `nombre` | String | Nombre completo del usuario | DynamoDB |
| 3 | `email` | String | Email del usuario | DynamoDB |
| 4 | `fecha_primera_conversacion` | String | Primera interacci√≥n con Catia | DynamoDB |
| 5 | `fecha_ultima_conversacion` | String | √öltima interacci√≥n registrada | DynamoDB |
| 6 | `numero_conversaciones` | Integer | Total de conversaciones | DynamoDB |
| 7 | `lista_preguntas` | String | Array JSON de preguntas completas | DynamoDB (JSON) |
| 8 | `feedback_likes` | Integer | Total de "Me gusta" | DynamoDB |
| 9 | `feedback_dislikes` | Integer | Total de "No me gusta" | DynamoDB |
| 10 | `feedback_ultima_respuesta` | String | Clasificaci√≥n: like/dislike/mixed | Calculado |
| 11 | `tokens_total` | Integer | Suma tokens conversaciones | Calculado (tiktoken) |
| 12 | `costo_estimado_usd` | Float | Costo AWS estimado | Calculado |

### **ü™ô Columnas del Dataset de Tokens Consolidado**

| # | Columna | Tipo | Descripci√≥n |
|---|---------|------|-------------|
| 1 | `create_date` | TIMESTAMP | Fecha/hora de creaci√≥n |
| 2 | `input_token` | INT | Tokens de entrada (prompt) |
| 3 | `output_token` | INT | Tokens de salida (respuesta) |
| 4 | `precio_token_input` | DECIMAL(10,6) | Costo tokens entrada |
| 5 | `precio_token_output` | DECIMAL(10,6) | Costo tokens salida |
| 6 | `total_price` | DECIMAL(10,6) | Costo total conversaci√≥n |
| 7 | `pk` | STRING | Partition Key DynamoDB |
| 8 | `sk` | STRING | Sort Key DynamoDB |
| 9 | `source` | STRING | Origen: `old_table` / `new_table` |

## üöÄ Deployment

### **üì¶ Prerequisitos**
```bash
npm install
npm run build
```

### **üåç Deploy Multi-Ambiente (Stack 3 - Tokens)**

```bash
# Deploy a TEST
cdk deploy cat-test-tokens-stack -c environment=test

# Deploy a PROD
cdk deploy cat-prod-tokens-stack -c environment=prod

# Deploy todos los stacks (incluyendo Normalize y ETL)
cdk deploy --all -c environment=prod
```

### **üîß Configuraci√≥n de Variables**

**Lambda ETL-1** (Stack 1):
```bash
S3_BUCKET_NAME=cat-prod-normalize-reports
OUTPUT_PREFIX=reports/etl-process1/
DYNAMODB_TABLE_NAME=BedrockChatStack-DatabaseConversationTable03F3FD7A-VCTDHISEE1NF
PROJECT_ID=P0260
ENVIRONMENT=PROD
CLIENT=CAT
```

**Lambda Tokens Archival** (Stack 3 - Lambda 1):
```bash
OLD_DYNAMODB_TABLE_NAME=BedrockChatStack-Old-Table
S3_BUCKET_NAME=cat-{env}-normalize-reports
S3_OLD_DATA_PREFIX=archival/tokens-analysis/
FILTER_DATE_START=2025-08-04  # Configurable por ambiente
FILTER_DATE_END=2025-11-30
ENVIRONMENT=TEST|PROD
```

**Lambda Tokens Consolidated** (Stack 3 - Lambda 2):
```bash
DYNAMODB_TABLE_NAME=BedrockChatStack-New-Table
S3_BUCKET_NAME=cat-{env}-normalize-reports
S3_OUTPUT_PREFIX=tokens-analysis/
S3_OLD_DATA_PREFIX=archival/tokens-analysis/
ATHENA_DATABASE=cat_{env}_analytics_db
ATHENA_WORKGROUP=wg-cat-{env}-analytics
FILTER_DATE_START=2026-01-01  # Fecha de migraci√≥n
ENVIRONMENT=TEST|PROD
```

**Glue Job ETL-2**:
```bash
--INPUT_PREFIX=reports/etl-process1/
--OUTPUT_PREFIX=reports/etl-process2/
--BUCKET_NAME=cat-prod-normalize-reports
```

### **üìä Configuraci√≥n de Horarios**

```typescript
// EventBridge Schedule - ETL-1 y ETL-2
schedule: events.Schedule.expression('cron(30 4 * * ? *)') // 11:30 PM Colombia

// EventBridge Schedule - Tokens (Stack 3)
// Test: Disabled (manual execution)
// Prod: cron(30 4 * * ? *) // 11:30 PM Colombia
```

### **üè∑Ô∏è Sistema de Tags para Cost Explorer**

| Tag | Valor | Prop√≥sito |
|-----|-------|----------|
| `Project` | `CAT-PROD-NORMALIZE`, `CAT-TOKENS-ANALYSIS` | Identificaci√≥n proyecto |
| `Environment` | `TEST`, `PROD` | Ambiente |
| `ETLComponent` | `ETL-1`, `ETL-2`, `TOKENS-ARCHIVAL`, `TOKENS-CONSOLIDATED` | Componente |
| `DataSource` | `DynamoDB-Old`, `DynamoDB-New` | Fuente datos |

## üß™ Testing y Validaci√≥n

### **üîç Tests Locales**

```bash
# Tests unitarios CDK
npm run test

# Test funci√≥n tokens archival local
cd lambda/tokens-process
python lambda-tokens-archival-processing.py

# Test funci√≥n tokens consolidated local
python tokens_lambda.py

# Test Lambda ETL-1 local
cd lambda/etl-process1
python -c "
import lambda_function
result = lambda_function.lambda_handler({}, {})
print(result)
"
```

### **üìä Monitoreo en Producci√≥n**

#### **CloudWatch Logs - Stack 3 (Tokens)**
```bash
# Logs Lambda Archival
aws logs tail /aws/lambda/cat-prod-lambda-tokens-archival-processing --follow

# Logs Lambda Consolidated
aws logs tail /aws/lambda/cat-prod-lambda-tokens --follow

# Logs ETL-1 Lambda
aws logs tail /aws/lambda/cat-prod-lambda-normalize --follow

# Logs ETL-2 Glue
aws logs tail /aws-glue/jobs/cat-prod-etl2-parquet --follow
```

#### **M√©tricas Clave por Stack**
| M√©trica | ETL-1 Lambda | ETL-2 Glue | Tokens Archival | Tokens Consolidated |
|---------|--------------|------------|-----------------|---------------------|
| **Duration** | < 15 min | < 10 min | < 15 min | < 5 min |
| **Memory** | < 1024 MB | N/A | 1-2 GB | 512 MB |
| **Frequency** | Daily | Auto (S3) | One-time | Daily (prod) |
| **Cost/d√≠a** | ~$0.10 | ~$0.50 | N/A | ~$0.02 |
| **Data Source** | DynamoDB Catia | S3 CSV | DynamoDB Old | DynamoDB New |

#### **Validaci√≥n de Datos**
```sql
-- Athena: Validar ETL-2 output
SELECT 
    COUNT(*) as total_usuarios,
    MIN(fecha_primera_conversacion) as fecha_min,
    MAX(fecha_primera_conversacion) as fecha_max,
    AVG(numero_conversaciones) as promedio_conversaciones
FROM cat_prod_analytics_db.data;

-- Athena: Validar tokens consolidados por origen
SELECT 
    source,
    COUNT(*) as conversaciones,
    SUM(input_token) as tokens_entrada,
    SUM(output_token) as tokens_salida,
    SUM(total_price) as costo_total_usd
FROM cat_{env}_analytics_db.tokens_table
GROUP BY source;

-- Athena: An√°lisis diario consolidado
SELECT 
    DATE(create_date) as fecha,
    source,
    COUNT(*) as registros,
    SUM(total_price) as costo_diario
FROM cat_prod_analytics_db.tokens_table
GROUP BY DATE(create_date), source
ORDER BY fecha DESC, source;
```

## ‚öôÔ∏è Comandos de Gesti√≥n

### **üìã Comandos CDK Principales**

| Comando | Descripci√≥n | Uso |
|---------|-------------|-----|
| `npm run build` | Compilar TypeScript | Antes de deploy |
| `npm run watch` | Compilaci√≥n autom√°tica | Desarrollo |
| `npx cdk synth` | Generar CloudFormation | Validaci√≥n |
| `npx cdk deploy --all` | Desplegar todos los stacks | Deploy completo |
| `npx cdk diff <stack>` | Ver cambios pendientes | Pre-deploy |
| `npx cdk destroy --all` | Eliminar todos los recursos | Cleanup |

### **üîÑ Operaciones por Stack y Ambiente**

```bash
# Deploy selectivo por stack
npx cdk deploy cat-prod-normalize-stack    # Solo ETL-1
npx cdk deploy cat-prod-etl2-stack         # Solo ETL-2  
npx cdk deploy cat-test-tokens-stack -c environment=test   # Tokens TEST
npx cdk deploy cat-prod-tokens-stack -c environment=prod   # Tokens PROD

# Ejecuci√≥n manual Lambda Archival (one-time)
aws lambda invoke \
  --function-name cat-prod-lambda-tokens-archival-processing \
  --payload '{}' \
  archival-response.json

# Ejecuci√≥n manual Lambda Consolidated
aws lambda invoke \
  --function-name cat-prod-lambda-tokens \
  --payload '{}' \
  consolidated-response.json

# Trigger manual ETL-1
aws lambda invoke \
  --function-name cat-prod-lambda-normalize \
  --payload '{}' \
  response.json

# Estado del Glue Job
aws glue get-job-runs --job-name cat-prod-etl2-parquet

# Verificar Crawler
aws glue get-crawler --name curated-crawler
```

### **üìä Consultas Athena de Validaci√≥n**

```sql
-- Verificar estructura tabla tokens consolidada
DESCRIBE tokens_table_consolidated;

-- KPIs consolidados de tokens
SELECT 
    source,
    COUNT(*) as total_conversaciones,
    SUM(input_token + output_token) as total_tokens,
    SUM(total_price) as costo_total_usd,
    AVG(total_price) as costo_promedio
FROM cat_prod_analytics_db.tokens_table
GROUP BY source;

-- Verificar integridad datos ETL-1 ‚Üí ETL-2
SELECT 
    table_name,
    column_name,
    data_type,
    is_nullable
FROM information_schema.columns 
WHERE table_schema = 'cat_prod_analytics_db'
ORDER BY table_name, ordinal_position;
```

## üìö Documentaci√≥n Adicional

- **Tokens Processing**: Ver `lambda/tokens-process/README.md` para detalles t√©cnicos del procesamiento dual
- **Lambda ETL**: Ver `lambda/README.md` para detalles de ETL-1 y ETL-2
- **Configuraci√≥n Multi-Ambiente**: Ver `lib/configs/` para configuraciones por ambiente

---

**√öltima actualizaci√≥n**: 2025-01-13  
**Versi√≥n Stack 3**: 2.0 (Dual Lambda + Multi-Ambiente)